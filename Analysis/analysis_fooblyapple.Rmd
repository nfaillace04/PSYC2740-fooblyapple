---
title: "analysis_fooblyapple"
ggeom_point(date: "2024-11-12"
---
#install and load packages
```{r}
#install.packages("tidyverse")
#install.packages("emmeans")
#install.packages("car")
#install.packages("sentimentr")
#install.packages("lmerTest")
#install.packages("performance")

library(tidyverse)
library(emmeans)
library(car)
library(sentimentr)
library(lmerTest)
library(performance)
```
#Import data
```{r}
sona_data = read.csv("../data/recentsonadata.csv") %>%
  select(-sona_id) %>% 
  mutate(data_source = "sona")

prolific_data = read.csv("../data/prolificdatanov22.csv")%>%
  select(-PROLIFIC_PID) %>% 
  mutate(data_source = "prolific")

final_data = rbind(sona_data, prolific_data) %>%
  mutate(rt = as.numeric(rt)) %>%
  mutate(valence = as.factor(valence)) %>%
  mutate(typeoftrial = as.factor(typeoftrial))

```
#Inspect data
```{r}
nrow(final_data)
ncol(final_data)

final_data %>%
pull(ID) %>% unique() %>% length

final_data %>%
  group_by(ID) %>% count()

final_data %>% 
  filter(typeoftrial == "target" & block_number == 1)%>%
  group_by(ID) %>%
  count()

final_data %>%
  group_by(ID) %>% filter(typeoftrial == "target") %>% count()

final_data %>%
  group_by(ID) %>% filter(typeoftrial == "sentence") %>% count() 

final_data %>%
  group_by(ID) %>% filter(typeoftrial == "attention") %>% count() 

```
There are 76215 rows and 43 columns in our data, and 147 unique subjects. All subjects that completed the experiment completed 105 target trials (9 practice and 96 experimental), 126 sentence trials, and 9 attention trials. All subjects did the same number of trials because unlike in the demographics survey, the number of trials should not change based on the responses of the subject.

Our independent variables are "valence" (positive, negative, neutral) and "type" (novel or familiar). Our dependent variables are "rt" for priming trials.

#Basic descriptives
```{r}
demographics = final_data %>%
 filter(typeoftrial == "demographics") %>%
  select(ID, age, gender, education, race, hispanic, dominant_hand, alert_time, english, age_learned_english) %>%
  mutate(across(c(age, education, age_learned_english), ~ replace_na(., NA))) %>%
  mutate(across(c(age, gender, education, race, hispanic, dominant_hand, alert_time, english), 
                ~ ifelse(. == "", "blank", .)))

subject_age = demographics %>%
summarise(mean_age = mean(age, na.rm = TRUE),
            sd_age = sd(age, na.rm = TRUE))

gender_distribution = demographics %>%
  filter(gender != "blank") %>%
  mutate(gender_cleaned = case_when(
    str_trim(gender) %in% c("Female", "female", "F", "FEMALE", "Female.", "Female/woman", "cis-women") ~ "Female",
    str_trim(gender) %in% c("Male", "male", "m", "M") ~ "Male",
    TRUE ~ "Other"
  )) %>%
  count(gender_cleaned)

race_distribution = demographics %>%
  filter(race != "blank") %>%
  count(race)

subject_education = demographics %>%
  summarise(mean_education = mean(education, na.rm = TRUE),
            sd_education = sd(education, na.rm = TRUE))

target_accuracy = final_data %>%
  filter(typeoftrial == "target") %>%
  group_by(ID) %>%
  summarise(correct_count = sum(correct == TRUE, na.rm = TRUE),
    total_count = n(),                                    
    accuracy = correct_count / total_count)

mean_target_accuracy = target_accuracy %>%
  summarise(mean_accuracy = mean(accuracy),
            sd_accuracy = sd(accuracy))
 
final_data %>%
  filter(typeoftrial == "target") %>%
  filter(rt < 1500) %>%
ggplot()+
  geom_histogram(mapping = aes (x = rt), binwidth = 30, na.rm = TRUE)+
 labs(title = "Histogram of Mean Response Time",
       x = "Mean Response Time",
       y = "Count") +
  theme_classic()

attention = final_data %>%
  filter(typeoftrial == "attention") %>%
  select(ID, response, novel, correct) %>%
  rowwise() %>%
  mutate(response = ifelse(is.na(response), "blank", response)) %>%
mutate(across(c(novel), ~ replace_na(., "NOT_FOUND"))) %>%
  mutate(edit_novel = adist(novel, response))%>%
  mutate(revised_correct = ifelse (edit_novel < 3, 1, 0),
         mismatch = ifelse (correct == revised_correct, 0, 1)) %>%
  ungroup()

subject_attention_accuracy = attention %>%
  group_by(ID) %>%
  summarise(mean_accuracy = mean(revised_correct, na.rm = TRUE),
            sd_accuracy = sd(revised_correct, na.rm = TRUE))

```
The mean age of our sample is 36.01, and the standard deviation is 12.88. The gender distribution is currently 77 females and 52 males. In terms of the racial distribution, there is 1 subject who identified as American Indian/Alaskan Native, 9 as Asian, 23 as Black/African American, 84 as White/Caucasian, 6 as multiracial, and 6 as other. The mean number of years of education in our sample was 15.51, with a standard deviation of 3.16.

The average accuracy in the target trials was 0.87, with a standard deviation of 0.13. 


#Inferential statistics
```{r}
low_acc_IDs = subject_attention_accuracy %>%
  filter(mean_accuracy < 0.75) %>%
  select(ID, mean_accuracy)

low_acc_IDs_vector = low_acc_IDs$ID %>%
  length()

revised_critical_data = final_data %>%
  filter(block_number == 1) %>%
  select(ID, rt, condition, prime, correct, target, correct_key, block_number, typeoftrial) %>%
  filter(!is.na(rt), rt > 200, rt < 1500, correct == TRUE) %>%
  anti_join(low_acc_IDs, by = "ID") 

included_in_priming = revised_critical_data %>%
  pull(ID) %>%
  unique() %>%
  length()

valence_codes = read_csv("../data/valence_codes.csv")

revised_critical_data = revised_critical_data %>% 
  filter(typeoftrial == "target" & block_number == 1)%>%
  select(ID, condition, rt, prime, target, correct) %>%
  left_join(valence_codes) %>% # for foobly, dodish, nuppical, mipp
  filter(!(prime %in% c("boff", "geck")))

revised_critical_data %>%
  group_by(ID) %>% count()

counts = revised_critical_data %>%
  group_by(valence) %>%
  count()

mean_scores = revised_critical_data %>%
  group_by(valence) %>%
  summarize(mean_rt = mean(rt),
           sd_rt = sd(rt)) %>%
  left_join(counts) %>%
  mutate(SE = sd_rt/sqrt(n),
         ymin = mean_rt - 1.96*SE,
         ymax = mean_rt + 1.96*SE)
  
mean_scores %>%
  group_by(valence) %>%
    ggplot() +
    geom_col(mapping = aes(x = valence, y = mean_rt,
                           group = valence, fill = valence),
             position = "dodge")+
  geom_errorbar(aes(x = valence, ymin = ymin, ymax = ymax),
                width = .25,
                position = position_dodge(width=0.9)) + 
  geom_point(data = mean_scores, aes(x = valence, y=mean_rt, colour = valence),
             position = position_jitterdodge(),
             alpha = 0.3)+
    theme_classic()

rt_model = lmer(data = revised_critical_data,
                rt ~ valence + (1|ID))
car::Anova(rt_model)
nobs(rt_model)

meaning_check = final_data %>%
  filter(typeoftrial == "meaning_check") %>%
  select(ID, condition, response, cue) %>%
  filter(str_count(response, "\\S+") >= 3)
 
meaning_check_correct = meaning_check %>%
  mutate(prime = str_extract(cue, "\\S+$"),
    correct = if_else(str_detect(str_to_lower(response), str_to_lower(prime)), "TRUE", "FALSE"))

revised_meaning_check = meaning_check_correct %>%
  filter(correct == "TRUE")
  
#meaning_check_sentiment
mc_sentiment_score = sentiment(revised_meaning_check$response)

aggregated_scores = mc_sentiment_score %>%
  group_by(element_id) %>% 
  summarise(sentiment = mean(sentiment),
    word_count = sum(word_count))

meaning_check_sentiment = revised_meaning_check %>%
  mutate(element_id = row_number()) %>%
  left_join(aggregated_scores, by = "element_id") %>% 
  select(-element_id, -word_count) %>%
  left_join(valence_codes, by = c("prime", "condition"))

meaning_check_sentiment %>%
  ggplot(aes(x = valence, y = sentiment)) +
  geom_boxplot() +
  theme_linedraw() +
  labs(title = "Boxplot of Meaning Check Sentiment Compared to Intended Valence", x = "Valence", y = "Sentiment")

meaning_check_model = lmer(data = meaning_check_sentiment,
                sentiment ~ valence + (1|ID))
car::Anova(meaning_check_model)
nobs(meaning_check_model)
emmeans::emmeans(meaning_check_model, pairwise ~ valence, adjust = "tukey")
```
Primary research question: To what extent does word valence impact word recognition? Operationalized by response times.

Based on the bar graph, the positive mean_rt appears higher than all the other valence levels. The unrelated valence seems to be only slightly lower than the rest and mean_rt for negative and neutral conditions appear comparable.

Our statistical tests indicated that there was no main effect of valence on reaction time, chi-square(3, N = 4396) = 2.181 p = .536.

Our testing suggested there was a main effect of valence on sentiment score, chi-square(2, N = 749) = 99.908, p < .001.

Follow-up Tukey p adjustment tests for pairwise comparison indicate that sentence responses in the positive valence condition had the strongest association with the novel word, (t(575) = 0.1375, followed by neutral, t(579) = 0.0329, and negative valence is associated with the weakest association, t(578) = -0.0387. All pairwise comparisons confirm that these differences are statistically significant (p < 0.001). We can conclude that our subjects were largely able to accurately associate novel words with their conditional valence.

Exclusions: The number of participants initially recruited was 147. We excluded 57 participants based on pre-registration criteria, and another 10 for not completing all parts of the experiment. In our models, we analyzed the data from 80 participants total. 

##Sentence boxplot
```{r}
directory = "../Experiment"

# Get a list of CSV files that match the pattern
all_csv_files = list.files(directory, pattern = "^valence_sentences.*-updated\\.csv$", full.names = TRUE)

# Read and combine all CSV files into one data frame called 'sentences'
sentences = all_csv_files %>%
  purrr::map_dfr(read_csv) %>%
  mutate(element_id = row_number()) %>%
  select(-part)

sentence_sentiment_score = sentiment(sentences$sentence)

aggregated_sentence_scores = sentence_sentiment_score %>%
  group_by(element_id) %>% 
  summarise(sentiment = mean(sentiment),
    word_count = sum(word_count))

sentences = sentences %>%
  left_join(aggregated_sentence_scores, by = "element_id") %>%
  select(-word_count)

sentences %>%
  ggplot(aes(x = valence, y = sentiment)) +
  geom_boxplot() +
  theme_linedraw() +
  labs(title = "Boxplot of Sentence Sentiment", x = "Valence", y = "Sentiment")
```


