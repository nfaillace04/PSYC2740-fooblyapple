---
title: "analysis_fooblyapple"
ggeom_point(date: "2024-11-12"
---
#install and load packages
```{r}
#install.packages("tidyverse")
#install.packages("emmeans")
#install.packages("car")
#install.packages("sentimentr")
#install.packages("lmerTest")

library(tidyverse)
library(emmeans)
library(car)
library(sentimentr)
library(lmerTest)
```
#import data
#CHANGE THIS FOR NEW DATA
```{r}
sona_data = read.csv("../data/firstsonadata.csv") %>%
  select(-sona_id) %>% 
  mutate(data_source = "sona")

prolific_data = read.csv("../data/firstprolificdata.csv")%>%
  select(-PROLIFIC_PID) %>% 
  mutate(data_source = "prolific")

final_data = rbind(sona_data, prolific_data)

```
#inspect data
```{r}
nrow(final_data)
ncol(final_data)

final_data %>%
pull(ID) %>% unique() %>% length

final_data %>%
  group_by(ID) %>% count()

final_data %>% 
  filter(typeoftrial == "target" & block_number == 1)%>%
  group_by(ID) %>%
  mutate(rt = as.numeric(rt)) %>%
  count()

#Our independent variables are "valence" (positive, negative, neutral) and "type" (novel or familiar).
#Our dependent variables are "rt" for priming trials.
as.factor(final_data$valence)
as.factor(final_data$type)

final_data %>%
  group_by(ID) %>% filter(typeoftrial == "target") %>% count()

final_data %>%
  group_by(ID) %>% filter(typeoftrial == "sentence") %>% count() 

final_data %>%
  group_by(ID) %>% filter(typeoftrial == "attention") %>% count() 

```
If number of target trials is not 105, exclude from data. If meaningchecks don't equal 6, exclude

#Basic descriptives
```{r}
demographics = final_data %>%
 filter(typeoftrial == "demographics") %>%
  select(ID, age, gender, education, race, hispanic, dominant_hand, alert_time, english) %>%
  mutate(across(c(age, education), ~ replace_na(., NA))) %>%
  mutate(across(c(gender, race, hispanic, dominant_hand, alert_time, english), 
                ~ replace_na(., "NOT_FOUND"))) %>%
  mutate(across(c(age, gender, education, race, hispanic, dominant_hand, alert_time, english), 
                ~ ifelse(. == "", "blank", .)))

subject_age = demographics %>%
summarise(mean_age = mean(age, na.rm = TRUE),
            sd_age = sd(age, na.rm = TRUE))

gender_distribution = demographics %>%
  filter(gender != "blank") %>%
  count(gender)

race_distribution = demographics %>%
  filter(race != "blank") %>%
  count(race)

subject_education = demographics %>%
  summarise(mean_education = mean(education, na.rm = TRUE),
            sd_education = sd(education, na.rm = TRUE))

target_accuracy = final_data %>%
  filter(typeoftrial == "target") %>%
  group_by(ID) %>%
  summarise(correct_count = sum(correct == TRUE, na.rm = TRUE),
    total_count = n(),                                    
    accuracy = correct_count / total_count)

mean_target_accuracy = target_accuracy %>%
  summarise(mean_accuracy = mean(accuracy),
            sd_accuracy = sd(accuracy))

target_data = final_data %>%
  filter(typeoftrial == "target") %>%
  group_by(ID)%>%
  mutate(rt = as.numeric(rt))

ggplot(data = target_data)+
  geom_histogram(mapping = aes (x = rt))
range(as.numeric(target_data$rt))

attention = final_data %>%
  filter(typeoftrial == "attention") %>%
  select(ID, response, novel, correct) %>%
  rowwise() %>%
  mutate(response = ifelse(is.na(response), "blank", response)) %>%
mutate(across(c(novel), ~ replace_na(., "NOT_FOUND"))) %>%
  mutate(edit_novel = adist(novel, response))%>%
  mutate(revised_correct = ifelse (edit_novel < 3, 1, 0), #changed to three letters difference as criterion for correct
         mismatch = ifelse (correct == revised_correct, 0, 1)) %>%
  ungroup()

meaning_check = final_data %>%
  filter(typeoftrial == "meaning_check") %>%
  select(ID, condition, response, cue) #encountered that we do not have the target stimulus word saved anywhere, so not sure how to determine what is correct.

subject_attention_accuracy = attention %>%
  group_by(ID) %>%
  summarise(mean_accuracy = mean(revised_correct, na.rm = TRUE),
            sd_accuracy = sd(revised_correct, na.rm = TRUE))

```
#Inferential Statistics

Primary research question: To what extent does word valence impact word recognition? Operationalized by response times.
```{r}
low_acc_IDs = subject_attention_accuracy %>%
  filter(mean_accuracy < 0.75) %>%
  pull(ID)

revised_critical_data = target_data %>%
  filter(block_number == 1) %>%
  select(ID, rt, condition, prime, correct, target, correct_key, block_number) %>%
  filter(!is.na(rt), rt > 200, rt < 1500, correct == TRUE) %>%
  filter(!ID %in% low_acc_IDs)
# we will also add a fluency exclusion to our real data by adding age_learned to target_data and excluding when age_learned > 4. we cannot do it with our pilot data because the column age_learned does not exist in this dataset.
```

# priming

```{r}
valence_codes = read_csv("../data/valence_codes.csv")

priming_data = final_data %>% 
  filter(typeoftrial == "target" & block_number == 1)%>%
  select(condition, rt, prime, target, correct) %>%
  left_join(valence_codes) #make sure to filter "dodish" "foobly" "nuppical" "mipp"
```


